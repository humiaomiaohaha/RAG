import json
import os
import numpy as np
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
import faiss
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
import pickle
import requests

class MedicalRAGSystem:
    def __init__(self, model_path: str = "D:\\Embedding\\Embedding", deepseek_api_key: str = "sk-b87c9bf17adf4c5d935feb2748534da4"):
        """
        åˆå§‹åŒ–åŒ»ç–—RAGç³»ç»Ÿ

        Args:
            model_path: æœ¬åœ°embeddingæ¨¡å‹è·¯å¾„
            deepseek_api_key: DeepSeek APIå¯†é’¥
        """
        self.model_path = model_path
        self.deepseek_api_key = deepseek_api_key
        self.deepseek_api_url = "https://api.deepseek.com/v1/chat/completions"

        try:
            # å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹
            self.embedding_model = SentenceTransformer(model_path)
            print(f"âœ… æˆåŠŸä»æœ¬åœ°è·¯å¾„åŠ è½½embeddingæ¨¡å‹: {model_path}")
        except Exception as e:
            print(f"âŒ æ— æ³•ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹ '{model_path}': {e}")
            print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ¨¡å‹...")
            try:
                self.embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
                self.model_path = "all-MiniLM-L6-v2"
                print("âœ… æˆåŠŸåŠ è½½å¤‡ç”¨embeddingæ¨¡å‹")
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨æ¨¡å‹ä¹ŸåŠ è½½å¤±è´¥: {e2}")
                raise RuntimeError("æ— æ³•åŠ è½½ä»»ä½•embeddingæ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„")
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            length_function=len,
        )
        self.index = None
        self.documents = []
        self.document_metadata = []

    def load_documents(self, file_path: str = "medical_docs.json"):
        """
        åŠ è½½åŒ»ç–—æ–‡æ¡£æ•°æ®

        Args:
            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡æ¡£æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")

        with open(file_path, 'r', encoding='utf-8') as f:
            docs = json.load(f)

        # è½¬æ¢ä¸ºLangChain Documentæ ¼å¼
        for doc in docs:
            # åˆ†å‰²é•¿æ–‡æœ¬
            chunks = self.text_splitter.split_text(doc['text'])
            for i, chunk in enumerate(chunks):
                self.documents.append(chunk)
                self.document_metadata.append({
                    'doc_id': doc['doc_id'],
                    'source': doc['source'],
                    'chunk_id': i,
                    'original_text': doc['text']
                })

        print(f"å·²åŠ è½½ {len(self.documents)} ä¸ªæ–‡æ¡£å—")

    def create_vector_index(self):
        """åˆ›å»ºFAISSå‘é‡ç´¢å¼•"""
        if not self.documents:
            raise ValueError("è¯·å…ˆåŠ è½½æ–‡æ¡£")

        # è®¡ç®—æ–‡æ¡£åµŒå…¥å‘é‡
        embeddings = self.embedding_model.encode(self.documents, show_progress_bar=True)

        # åˆ›å»ºFAISSç´¢å¼•
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)  # ä½¿ç”¨å†…ç§¯ç›¸ä¼¼åº¦

        # å½’ä¸€åŒ–å‘é‡ï¼ˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        faiss.normalize_L2(embeddings)

        # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        self.index.add(embeddings.astype('float32'))

        print(f"å·²åˆ›å»ºå‘é‡ç´¢å¼•ï¼ŒåŒ…å« {self.index.ntotal} ä¸ªå‘é‡")

    def search_documents(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸å…³æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡

        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        if self.index is None:
            raise ValueError("è¯·å…ˆåˆ›å»ºå‘é‡ç´¢å¼•")

        # è®¡ç®—æŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)

        # æœç´¢ç›¸ä¼¼æ–‡æ¡£
        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)

        # è¿”å›ç»“æœ
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx < len(self.documents):
                results.append({
                    'content': self.documents[idx],
                    'metadata': self.document_metadata[idx],
                    'score': float(score)
                })

        return results

    def generate_answer(self, query: str, context_docs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç”Ÿæˆç­”æ¡ˆï¼ˆä½¿ç”¨æ¨¡æ‹ŸAPIï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context_docs: ç›¸å…³æ–‡æ¡£åˆ—è¡¨

        Returns:
            åŒ…å«ç­”æ¡ˆå’Œæ¥æºçš„å­—å…¸
        """
        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n".join([doc['content'] for doc in context_docs])

        # è°ƒç”¨DeepSeek API
        api_response = self._call_deepseek_api(query, context)

        # æå–æ¥æºä¿¡æ¯
        sources = []
        for doc in context_docs:
            sources.append({
                'doc_id': doc['metadata']['doc_id'],
                'source': doc['metadata']['source'],
                'content': doc['content'][:100] + "..."  # æˆªå–å‰100ä¸ªå­—ç¬¦
            })

        return {
            'answer': api_response,
            'sources': sources,
            'query': query
        }

    def _call_deepseek_api(self, query: str, context: str) -> str:
        """
        è°ƒç”¨DeepSeek APIç”Ÿæˆç­”æ¡ˆ

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        # æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥
        if not self.deepseek_api_key or self.deepseek_api_key == "YOUR_DEEPSEEK_API_KEY":
            print("âš ï¸ DeepSeek APIå¯†é’¥æœªè®¾ç½®ï¼Œä½¿ç”¨æœ¬åœ°ç­”æ¡ˆç”Ÿæˆ")
            return self._generate_fallback_answer(query, context)

        # å…ˆæµ‹è¯•ç½‘ç»œè¿æ¥
        try:
            test_response = requests.get("https://api.deepseek.com", timeout=5)
            if test_response.status_code != 200:
                print("âš ï¸ DeepSeek APIæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°ç­”æ¡ˆç”Ÿæˆ")
                return self._generate_fallback_answer(query, context)
        except Exception as e:
            print(f"âš ï¸ ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨æœ¬åœ°ç­”æ¡ˆç”Ÿæˆ: {e}")
            return self._generate_fallback_answer(query, context)

        # å¦‚æœç½‘ç»œæµ‹è¯•é€šè¿‡ï¼Œå°è¯•è°ƒç”¨API
        print("ğŸŒ ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œå°è¯•è°ƒç”¨DeepSeek API...")

        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.deepseek_api_key}",
                "User-Agent": "MedicalRAGSystem/1.0"
            }

            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„åŒ»ç–—æ–‡çŒ®å†…å®¹ï¼Œç®€æ´ã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ–‡çŒ®ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"
                },
                {
                    "role": "user",
                    "content": f"ä»¥ä¸‹æ˜¯ç›¸å…³åŒ»ç–—æ–‡çŒ®å†…å®¹ï¼š\n\n{context}\n\nè¯·å›ç­”é—®é¢˜ï¼š{query}"
                }
            ]

            payload = {
                "model": "deepseek-chat",
                "messages": messages,
                "max_tokens": 1000,
                "temperature": 0.7
            }

            print("â³ æ­£åœ¨è°ƒç”¨DeepSeek API...")
            # ç¦ç”¨ä»£ç†è®¾ç½®
            session = requests.Session()
            session.trust_env = False  # ä¸ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®

            response = session.post(
                self.deepseek_api_url,
                headers=headers,
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                answer = result['choices'][0]['message']['content']
                print("âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ")
                return answer
            else:
                print(f"âŒ DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯ä½™é¢ä¸è¶³
                if "Insufficient Balance" in response.text:
                    print("ğŸ’° APIå¯†é’¥ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼æˆ–ä½¿ç”¨æœ¬åœ°æ¨¡å¼")
                elif response.status_code == 401:
                    print("ğŸ”‘ APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®")
                elif response.status_code == 429:
                    print("â±ï¸ APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•")
                else:
                    print("â“ æœªçŸ¥APIé”™è¯¯")

                return self._generate_fallback_answer(query, context)

        except Exception as e:
            print(f"âŒ DeepSeek APIè°ƒç”¨å¼‚å¸¸: {e}")
            return self._generate_fallback_answer(query, context)

    def _generate_fallback_answer(self, query: str, context: str) -> str:
        """ç”Ÿæˆå¤‡ç”¨ç­”æ¡ˆ"""
        if "é“¶å±‘ç—…" in query and "ç”Ÿç‰©åˆ¶å‰‚" in query:
            return """æ ¹æ®ç›¸å…³åŒ»å­¦æ–‡çŒ®ï¼Œé“¶å±‘ç—…çš„ç”Ÿç‰©åˆ¶å‰‚ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ç±»ï¼š

1. TNF-Î±æŠ‘åˆ¶å‰‚ï¼šå¦‚é˜¿è¾¾æœ¨å•æŠ—
2. IL-17æŠ‘åˆ¶å‰‚ï¼šå¦‚å¸åº“å¥‡å°¤å•æŠ—
3. IL-23æŠ‘åˆ¶å‰‚ï¼šå¦‚å¤å¡å¥‡å°¤å•æŠ—

è¿™äº›ç”Ÿç‰©åˆ¶å‰‚åœ¨ä¸´åºŠå®è·µä¸­æ˜¾ç¤ºå‡ºè‰¯å¥½çš„ç–—æ•ˆå’Œå®‰å…¨æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„æ‚£è€…çš„PASIè¯„åˆ†ã€‚é•¿æœŸå®‰å…¨æ€§è¯„ä¼°æ˜¾ç¤ºï¼Œä¸¥é‡æ„ŸæŸ“ã€æ¶æ€§è‚¿ç˜¤å’Œå¿ƒè¡€ç®¡äº‹ä»¶çš„å‘ç”Ÿç‡ä¸æ™®é€šäººç¾¤ç›¸å½“ã€‚

æ¥æºï¼šç›¸å…³åŒ»å­¦æ–‡çŒ®ç ”ç©¶"""

        elif "æ¹¿ç–¹" in query or "ç‰¹åº”æ€§çš®ç‚" in query:
            return """ç‰¹åº”æ€§çš®ç‚çš„æ²»ç–—æ–¹æ³•åŒ…æ‹¬ï¼š

å¤–ç”¨æ²»ç–—ï¼š
- é’™è°ƒç¥ç»é…¶æŠ‘åˆ¶å‰‚
- ç³–çš®è´¨æ¿€ç´ 
- JAKæŠ‘åˆ¶å‰‚å¤–ç”¨åˆ¶å‰‚ï¼ˆå¦‚æ‰˜æ³•æ›¿å°¼ï¼‰

ç”Ÿç‰©åˆ¶å‰‚æ²»ç–—ï¼š
- åº¦æ™®åˆ©å°¤å•æŠ—ï¼ˆé¦–ä¸ªè·æ‰¹çš„ç”Ÿç‰©åˆ¶å‰‚ï¼‰
- é€šè¿‡é¶å‘IL-4å’ŒIL-13ä¿¡å·é€šè·¯å‘æŒ¥ä½œç”¨

è¿™äº›æ²»ç–—æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æ”¹å–„æ‚£è€…çš„ç˜™ç—’ç—‡çŠ¶å’Œçš®æŸä¸¥é‡ç¨‹åº¦ã€‚

æ¥æºï¼šç›¸å…³åŒ»å­¦æ–‡çŒ®ç ”ç©¶"""

        else:
            return f"""åŸºäºæä¾›çš„åŒ»å­¦æ–‡çŒ®ï¼Œå…³äº"{query}"çš„ç›¸å…³ä¿¡æ¯å¦‚ä¸‹ï¼š

{context[:200]}...

å»ºè®®å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿè·å–æ›´è¯¦ç»†çš„è¯Šç–—å»ºè®®ã€‚

æ¥æºï¼šç›¸å…³åŒ»å­¦æ–‡çŒ®ç ”ç©¶"""

    def save_index(self, file_path: str = "faiss_index.pkl"):
        """ä¿å­˜å‘é‡ç´¢å¼•"""
        if self.index is None:
            raise ValueError("æ²¡æœ‰å¯ä¿å­˜çš„ç´¢å¼•")

        with open(file_path, 'wb') as f:
            pickle.dump({
                'index': self.index,
                'documents': self.documents,
                'metadata': self.document_metadata
            }, f)
        print(f"ç´¢å¼•å·²ä¿å­˜åˆ° {file_path}")

    def load_index(self, file_path: str = "faiss_index.pkl"):
        """åŠ è½½å‘é‡ç´¢å¼•"""
        if not os.path.exists(file_path):
            raise ValueError(f"ç´¢å¼•æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")

        with open(file_path, 'rb') as f:
            data = pickle.load(f)

        self.index = data['index']
        self.documents = data['documents']
        self.document_metadata = data['metadata']

        print(f"å·²åŠ è½½ç´¢å¼•ï¼ŒåŒ…å« {len(self.documents)} ä¸ªæ–‡æ¡£")

    def query(self, question: str, top_k: int = 3) -> Dict[str, Any]:
        """
        å®Œæ•´çš„æŸ¥è¯¢æµç¨‹

        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: æ£€ç´¢çš„æ–‡æ¡£æ•°é‡

        Returns:
            åŒ…å«ç­”æ¡ˆå’Œæ¥æºçš„å®Œæ•´ç»“æœ
        """
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        relevant_docs = self.search_documents(question, top_k)

        # ç”Ÿæˆç­”æ¡ˆ
        result = self.generate_answer(question, relevant_docs)

        return result

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    rag = MedicalRAGSystem()

    # åŠ è½½æ–‡æ¡£
    rag.load_documents()

    # åˆ›å»ºå‘é‡ç´¢å¼•
    rag.create_vector_index()

    # ä¿å­˜ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
    rag.save_index()

    # æµ‹è¯•æŸ¥è¯¢
    test_question = "é“¶å±‘ç—…ç”Ÿç‰©åˆ¶å‰‚æœ‰å“ªäº›ï¼Ÿ"
    result = rag.query(test_question)

    print(f"é—®é¢˜: {result['query']}")
    print(f"ç­”æ¡ˆ: {result['answer']}")
    print("\næ¥æº:")
    for source in result['sources']:
        print(f"- {source['source']} ({source['doc_id']})")